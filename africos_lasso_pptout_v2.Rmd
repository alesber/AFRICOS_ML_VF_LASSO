---
title: "Classification of Viral Failure in AFRICOS (Enrollment Visit)"
author: "Allahna Esber"
date: "5 April 2021"
output: powerpoint_presentation
slide_level: 3 # 3 hashtags indicate start new slide
---

```{r message=F, warning=F, echo=F}
# installing/loading the package
# if(!require(installr)) { install.packages("installr"); require(installr)} #load / install+load installr

# Installing pandoc
# install.pandoc()

# rmarkdown::pandoc_version()

library(rmarkdown)
library(sjPlot)
library(readstata13)
library(glmnet)
library(MASS)
library(caret)
library(dplyr)
library(tidyr)
library(tidyverse)
library(c060)
library(peperr)
library(pscl)
library(pROC)
library(ggplot2)
library(generalhoslem)
library(gtsummary)
library(table1)
test <- read.dta13("ml_analysis_v1_onart_v3.dta", generate.factors=T, nonint.factors=T)
vis1 <- test[which(test$visit==1),]

#Removing any missing values
vis1 = na.omit(vis1)
A2=vis1[,c(1,3,5:15, 17:100, 102)]


variable.names = colnames(A2)
boolean = !(variable.names %in% 'vf')
Xdataframe = A2[,boolean]
Yvariable = A2[,!boolean]
Yvariable <-  factor(A2$vf) 
Xdataframe <- as.data.frame(Xdataframe)  # Converts tibble to data frame


#converting variables to fact0r 
names <- c(1:4,6:12,14:24,26:74,76:81, 83:86, 89:97) 
namesvf <- c(1:4,6:12,14:24,26:74,76:81, 83:86, 89:98) 
Xdataframe[,names]<-lapply(Xdataframe[,names],factor)
A2[,namesvf]<-lapply(A2[,namesvf],factor)

some.matrix <-data.matrix(Xdataframe) #converts dataframe to matrix 
```
### Objectives

Research aim: To determine the clinical, demographic and behavioral predictors of virologic failure among participants enrolled in AFRICOS.   

  **1. To determine factors associated with viral load at the enrollment visit.**  
  2. To longitudinally assess factors associated with viral load   
  3. To quantify time to virologic failure  

### Variables for inclusion
```{r message=F, warning=F, echo=F}
names(Xdataframe)
```
### Data cleaning
* If missing demographic variables like education, sex, total number in household, imputed from visit two
* Missing height, weight, BMI, elevated BP, PTSD also carried over from visit two
* Added option 'NA/male' for variables only assessed for females (cervical cancer screening, parity)
* Added option NA/ART naive for ART related variables
* Participants missing information on new dx or current client categorized as current client if dx date> 0.25 years prior to enrollment date

### Lasso regression methods summary 
* Objective of lasso regression is to penalize parameters and shrink coefficients to zero.
* Select min lambda using cross validation (10-fold)
* 5 options to use for selecting loss to use for cross-validation:
  + Deviance
  + Misclassification error
  + AUC (area under the ROC curve)
  + MSE (mean squared error)- measures the deviation from the fitted mean to the response
  + MAE (mean absolute error)- measures the deviation from the fitted mean to the response 
* Run on full dataset
* Display coefficients based on selected lambda

### Table 1
```{r message=F, warning=F, echo=F}
kable()
table1(~ progid + agev + gender + dur_art + ARTp | vf, dat=A2)
```

### Shrinkage plot- Full model

```{r message=F, warning=F, echo=F}
out = glmnet(some.matrix, Yvariable, alpha = 1, family="binomial") # Fit lasso model on full dataset
plot(out, xvar="lambda")


```
### Lasso regression- Deviance


```{r message=F, warning=F, echo=F}
#lasso regression
set.seed(501)
dev.out = cv.glmnet(some.matrix, Yvariable, alpha = 1, family="binomial", type.measure = "deviance", nfolds= 10) # Fit lasso model on training data
plot(dev.out) # Draw plot of training deviance as a function of lambda
devlam = dev.out$lambda.1se# select lambda + 1 
lasso_dev = predict(out, type = "coefficients", s = devlam)[1:97,] 
lasso_dev[lasso_dev!= 0]
```

### Lasso regression- Deviance
```{r message=F, warning=F, echo=F}
out = glmnet(some.matrix, Yvariable, alpha = 1, family="binomial") # Fit lasso model on full dataset
plot(out, xvar="lambda")
lasso_dev = predict(out, type = "coefficients", s = devlam)[1:98,] 
lasso_dev[lasso_dev!= 0]
assess.glmnet(dev.out, newx = some.matrix, newy = Yvariable)

```
### Logistic Regression output- Deviance 
```{r message=F, warning=F, echo=F}
logdev <- glm(vf ~  progid +  missarv  + agev +  cd4_cat, data=A2, family = "binomial")
summary(logdev)
pR2(logdev)
logitgof(A2$vf, fitted(logdev))
tbl_regression(logdev, exponentiate= TRUE)


```
### Logistic Regression- ORs
```{r message=F, warning=F, echo=F}
exp(cbind(OR=coef(logdev), confint(logdev)))
tbl_regression(logdev, exponentiate= TRUE)
```

### ROC Curve for DEV
```{r message=F, warning=F, echo=F}
roc(A2$vf, as.vector(fitted.values(logdev)), percent=F,   boot.n=1000, ci.alpha=0.9, stratified=FALSE, plot=TRUE, grid=TRUE, show.thres=TRUE, legacy.axes = TRUE, reuse.auc = TRUE,
# print.thres = c(0.30,0.35, 0.40, 0.45,0.48, 0.50,0.55, 0.60),#
print.auc = TRUE, print.thres.col = "blue", ci=TRUE, ci.type="bars", print.thres.cex = 0.7, main = paste("ROC curve using","(N = ",nrow(A2),")") )
```

### Lasso regression- AUC
```{r message=F, warning=F, echo=F}
#lasso regression
set.seed(501)
auc.out = cv.glmnet(some.matrix, Yvariable, alpha = 1, family="binomial", type.measure = "auc", nfolds= 10) # Fit lasso model on training data
plot(auc.out) # Draw plot of training deviance as a function of lambda
auclam = auc.out$lambda.1se# select lambda + 1 SE
assess.glmnet(auc.out, newx = some.matrix, newy = Yvariable)
```


### Lasso regression- AUC

```{r message=F, warning=F, echo=F}
lasso_auc = predict(out, type = "coefficients", s = auclam)[1:98,] 
lasso_auc[lasso_auc!= 0]

```
### Logistic Regression output- AUC 
```{r message=F, warning=F, echo=F}
logauc <- glm(vf ~ progid + employed +  cho199  + dx11a17x4 + missarv  +  dur_art + kids + agev + cd4_cat, data=A2, family = "binomial")
summary(logauc)
pR2(logauc)
logitgof(A2$vf, fitted(logauc))
```
### Logistic Regression output- ORs 
```{r message=F, warning=F, echo=F}
exp(cbind(OR=coef(logauc), confint(logauc)))
tbl_regression(logauc, exponentiate= TRUE)
```
### ROC Curve for AUC
```{r message=F, warning=F, echo=F}
roc(A2$vf, as.vector(fitted.values(logauc)), percent=F,   boot.n=1000, ci.alpha=0.9, stratified=FALSE, plot=TRUE, grid=TRUE, show.thres=TRUE, legacy.axes = TRUE, reuse.auc = TRUE,
# print.thres = c(0.30,0.35, 0.40, 0.45,0.48, 0.50,0.55, 0.60),#
print.auc = TRUE, print.thres.col = "blue", ci=TRUE, ci.type="bars", print.thres.cex = 0.7, main = paste("ROC curve using","(N = ",nrow(A2),")") )
```

### Lasso regression- MSE
```{r message=F, warning=F, echo=F}
#lasso regression
set.seed(501)
mse.out = cv.glmnet(some.matrix, Yvariable, alpha = 1, family="binomial", type.measure = "mse", nfolds= 10) # Fit lasso model on training data
plot(mse.out) # Draw plot of training deviance as a function of lambda
mselam = mse.out$lambda.1se# select lambda + 1 SE
```


### Lasso regression- MSE

```{r message=F, warning=F, echo=F}
lasso_mse = predict(out, type = "coefficients", s = mselam)[1:98,] 
lasso_mse[lasso_mse!= 0]
assess.glmnet(mse.out, newx = some.matrix, newy = Yvariable)
```

### Logistic Regression output- MSE 
```{r message=F, warning=F, echo=F}
logmse <- glm(vf ~  progid  + missarv +  agev + cd4_cat , data=A2, family = "binomial")
summary(logmse)
pR2(logmse)
logitgof(A2$vf, fitted(logmse))
```
### Logistic Regression output- ORs
```{r message=F, warning=F, echo=F}
exp(cbind(OR=coef(logmse), confint(logmse)))
tbl_regression(logmse, exponentiate= TRUE)
```

### ROC Curve for MSE
```{r message=F, warning=F, echo=F}
roc(A2$vf, as.vector(fitted.values(logmse)), percent=F,   boot.n=1000, ci.alpha=0.9, stratified=FALSE, plot=TRUE, grid=TRUE, show.thres=TRUE, legacy.axes = TRUE, reuse.auc = TRUE,
# print.thres = c(0.30,0.35, 0.40, 0.45,0.48, 0.50,0.55, 0.60),#
print.auc = TRUE, print.thres.col = "blue", ci=TRUE, ci.type="bars", print.thres.cex = 0.7, main = paste("ROC curve using","(N = ",nrow(A2),")") )
```

### Lasso regression- MAE
```{r message=F, warning=F, echo=F}
#lasso regression
set.seed(501)
mae.out = cv.glmnet(some.matrix, Yvariable, alpha = 1, family="binomial", type.measure = "mae", nfolds= 10) # Fit lasso model on training data
plot(mae.out) # Draw plot of training deviance as a function of lambda
maelam = mae.out$lambda.1se# select lambda + 1 SE
```


### Lasso regression- MAE

```{r message=F, warning=F, echo=F}
lasso_mae = predict(out, type = "coefficients", s = maelam)[1:98,]
lasso_mae[lasso_mae!= 0]
assess.glmnet(mae.out, newx = some.matrix, newy = Yvariable)

```

### Logistic Regression output- MAE 
```{r message=F, warning=F, echo=F}
logmae <- glm(vf ~  progid  + gender + pristudy + readwrit + educat + employed + food + tb + pcpmed + tbiptmed + hcv + glu99 + cho199 + gfr60 + bp + dx1a_7e1 + dx8a_10f2 +  dx8a_10f1 +  dx8a_10f6 + dx11a17x4 + dx11a17x4 + missarv + arvsupp + hvste_a + whiv_a + whiv_b + whiv_g + alcohol +   fammhx_e + fammhx_f + dur_art + agev + cd4_cat + distance + visyr + cd4_cat + hivdur + disclose + cesdcat , data=A2, family = "binomial")
summary(logmae)
pR2(logmae)
logitgof(A2$vf, fitted(logmae))
tbl_regression(logmae, exponentiate= TRUE)

```
### Logistic Regression output- ORs
```{r message=F, warning=F, echo=F}
exp(cbind(OR=coef(logmae), confint(logmae)))
```

### ROC Curve for MAE
```{r message=F, warning=F, echo=F}
roc(A2$vf, as.vector(fitted.values(logmae)), percent=F,   boot.n=1000, ci.alpha=0.9, stratified=FALSE, plot=TRUE, grid=TRUE, show.thres=TRUE, legacy.axes = TRUE, reuse.auc = TRUE,
# print.thres = c(0.30,0.35, 0.40, 0.45,0.48, 0.50,0.55, 0.60),#
print.auc = TRUE, print.thres.col = "blue", ci=TRUE, ci.type="bars", print.thres.cex = 0.7, main = paste("ROC curve using","(N = ",nrow(A2),")") )

```




### Lasso regression- Misclassification Error
```{r message=F, warning=F, echo=F}
#lasso regression
set.seed(501)
class.out = cv.glmnet(some.matrix, Yvariable, alpha = 1, family="binomial", type.measure = "class", nfolds= 10) # Fit lasso model on training data
plot(class.out) # Draw plot of training deviance as a function of lambda
classlam = class.out$lambda.1se# select lambda + 1 SE
```


### Lasso regression- Misclassification Error

```{r message=F, warning=F, echo=F}
lasso_class = predict(out, type = "coefficients", s = classlam)[1:98,] 
lasso_class[lasso_class!= 0]
```
### Logistic Regression output-Misclassification error
```{r message=F, warning=F, echo=F}
logclass <- glm(vf ~  progid + employed + dx11a17x4 + missarv + dur_art + kids + agev + cd4_cat , data=A2, family = "binomial")
summary(logclass)
pR2(logclass)
logitgof(A2$vf, fitted(logclass))
```
### Logistic Regression- ORs
```{r message=F, warning=F, echo=F}
exp(cbind(OR=coef(logclass), confint(logclass)))

```
